"""
ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ì— ëŒ€í•´ pseudo-labelingì„ ìˆ˜í–‰í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ë°©ë²•:
1. ë¨¼ì € ë ˆì´ë¸”ì´ ìˆëŠ” ì´ë¯¸ì§€ë¡œ ëª¨ë¸ì„ í•™ìŠµ
2. í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ì— ì˜ˆì¸¡ ìˆ˜í–‰
3. ë†’ì€ confidenceì˜ ì˜ˆì¸¡ë§Œ JSON ì–´ë…¸í…Œì´ì…˜ íŒŒì¼ë¡œ ì €ì¥
"""

import os
import json
import glob
from pathlib import Path
from tqdm import tqdm
import torch
from ultralytics import YOLO
from PIL import Image


def find_images_without_annotations(base_dir, train_img_dir, train_ann_dir):
    """
    ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
    
    Args:
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        train_img_dir: í•™ìŠµ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        train_ann_dir: ì–´ë…¸í…Œì´ì…˜ ë””ë ‰í† ë¦¬
    
    Returns:
        ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    """
    # ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    all_images = set()
    for ext in ['.png', '.jpg', '.jpeg']:
        all_images.update([f.replace(ext, '') for f in os.listdir(train_img_dir) 
                          if f.lower().endswith(ext)])
    
    # ì–´ë…¸í…Œì´ì…˜ì´ ìˆëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
    json_files = glob.glob(os.path.join(train_ann_dir, "**/*.json"), recursive=True)
    annotated_images = set()
    
    for json_path in json_files:
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if 'images' in data and len(data['images']) > 0:
                    img_name = data['images'][0]['file_name']
                    img_name_no_ext = img_name.replace('.png', '').replace('.jpg', '').replace('.jpeg', '')
                    annotated_images.add(img_name_no_ext)
        except:
            continue
    
    # ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
    missing_images = []
    for img_name_no_ext in all_images:
        if img_name_no_ext not in annotated_images:
            # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            for ext in ['.png', '.jpg', '.jpeg']:
                img_path = os.path.join(train_img_dir, f"{img_name_no_ext}{ext}")
                if os.path.exists(img_path):
                    missing_images.append({
                        'name': img_name_no_ext,
                        'path': img_path,
                        'ext': ext
                    })
                    break
    
    return missing_images


def create_annotation_json(img_path, predictions, category_mapping, ann_id_start=1, conf_threshold=0.5):
    """
    ì˜ˆì¸¡ ê²°ê³¼ë¥¼ JSON ì–´ë…¸í…Œì´ì…˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    
    Args:
        img_path: ì´ë¯¸ì§€ ê²½ë¡œ
        predictions: YOLO ì˜ˆì¸¡ ê²°ê³¼
        category_mapping: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        ann_id_start: ì–´ë…¸í…Œì´ì…˜ ID ì‹œì‘ ë²ˆí˜¸
        conf_threshold: Confidence threshold
    
    Returns:
        JSON ì–´ë…¸í…Œì´ì…˜ ë”•ì…”ë„ˆë¦¬
    """
    # ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    img = Image.open(img_path)
    img_w, img_h = img.size
    
    # ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„
    img_name = os.path.basename(img_path)
    img_name_no_ext = img_name.replace('.png', '').replace('.jpg', '').replace('.jpeg', '')
    
    # ê¸°ë³¸ ì´ë¯¸ì§€ ì •ë³´ (ì‹¤ì œ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìœ¼ë©´ ë” ì¢‹ìŒ)
    image_info = {
        "file_name": img_name,
        "width": img_w,
        "height": img_h,
        "imgfile": img_name,
        "id": ann_id_start
    }
    
    # ì–´ë…¸í…Œì´ì…˜ ìƒì„±
    annotations = []
    categories = []
    category_ids_used = set()
    
    idx2cat = category_mapping.get('idx2cat', {})
    
    annotation_idx = 0
    for box in predictions.boxes:
        cls = int(box.cls)
        score = float(box.conf)
        
        # Confidence threshold ì²´í¬
        if score < conf_threshold:
            continue
        
        # í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ì¹´í…Œê³ ë¦¬ IDë¡œ ë³€í™˜
        if str(cls) not in idx2cat:
            continue
        
        category_id = int(idx2cat[str(cls)])
        category_ids_used.add(category_id)
        
        # YOLO í˜•ì‹ (ì •ê·œí™”ëœ ì¢Œí‘œ)ì„ COCO í˜•ì‹ (ì ˆëŒ€ ì¢Œí‘œ)ìœ¼ë¡œ ë³€í™˜
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
        x = float(x1)
        y = float(y1)
        w = float(x2 - x1)
        h = float(y2 - y1)
        area = w * h
        
        annotation = {
            "area": int(area),
            "iscrowd": 0,
            "bbox": [int(x), int(y), int(w), int(h)],
            "category_id": category_id,
            "ignore": 0,
            "segmentation": [],
            "id": ann_id_start + annotation_idx,
            "image_id": ann_id_start
        }
        annotations.append(annotation)
        annotation_idx += 1
    
    # ì¹´í…Œê³ ë¦¬ ì •ë³´ ìƒì„±
    # ì‹¤ì œ JSON íŒŒì¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ì´ë¦„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ ê¸°ë³¸ê°’ ì‚¬ìš©
    cat2name = category_mapping.get('cat2name', {})
    for cat_id in category_ids_used:
        category = {
            "supercategory": "pill",
            "id": cat_id,
            "name": cat2name.get(str(cat_id), f"category_{cat_id}")
        }
        categories.append(category)
    
    # JSON êµ¬ì¡° ìƒì„±
    annotation_data = {
        "images": [image_info],
        "type": "instances",
        "annotations": annotations,
        "categories": categories
    }
    
    return annotation_data


def generate_pseudo_labels(model_path, base_dir, train_img_dir, train_ann_dir, 
                          category_mapping_path, output_dir=None, 
                          conf_threshold=0.5, min_boxes=1):
    """
    ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ì— ëŒ€í•´ pseudo-labeling ìˆ˜í–‰
    
    Args:
        model_path: í•™ìŠµëœ YOLO ëª¨ë¸ ê²½ë¡œ
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        train_img_dir: í•™ìŠµ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        train_ann_dir: ì–´ë…¸í…Œì´ì…˜ ë””ë ‰í† ë¦¬
        category_mapping_path: ì¹´í…Œê³ ë¦¬ ë§¤í•‘ JSON íŒŒì¼ ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ train_ann_dir ì‚¬ìš©)
        conf_threshold: Confidence threshold (ê¸°ë³¸ê°’: 0.5)
        min_boxes: ìµœì†Œ ê²€ì¶œ ë°•ìŠ¤ ê°œìˆ˜ (ì´ë³´ë‹¤ ì ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ)
    """
    # ëª¨ë¸ ë¡œë“œ
    print(f"ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
    model = YOLO(model_path)
    
    # Category mapping ë¡œë“œ
    with open(category_mapping_path, 'r', encoding='utf-8') as f:
        category_mapping = json.load(f)
    
    # ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ ì°¾ê¸°
    print("\nì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ ì°¾ëŠ” ì¤‘...")
    missing_images = find_images_without_annotations(base_dir, train_img_dir, train_ann_dir)
    print(f"ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_images)}ê°œ")
    
    if len(missing_images) == 0:
        print("ì–´ë…¸í…Œì´ì…˜ì´ ì—†ëŠ” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    if output_dir is None:
        output_dir = train_ann_dir
    os.makedirs(output_dir, exist_ok=True)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {'GPU' if device == 0 else 'CPU'}")
    
    # Pseudo-labeling ìˆ˜í–‰
    generated_count = 0
    skipped_count = 0
    ann_id = 10000  # ê¸°ì¡´ ì–´ë…¸í…Œì´ì…˜ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ë†’ì€ ID ì‚¬ìš©
    
    # ë””ë²„ê¹…: ì˜ˆì¸¡ í†µê³„
    total_predictions = 0
    max_confidences = []
    
    print(f"\nPseudo-labeling ì‹œì‘ (conf_threshold={conf_threshold}, min_boxes={min_boxes})...")
    
    for idx, img_info in enumerate(tqdm(missing_images, desc="Pseudo-labeling")):
        img_path = img_info['path']
        img_name_no_ext = img_info['name']
        
        try:
            # ì˜ˆì¸¡ ìˆ˜í–‰ (confidence thresholdë¥¼ ë‚®ì¶°ì„œ ëª¨ë“  ì˜ˆì¸¡ í™•ì¸)
            results = model.predict(
                img_path,
                imgsz=800,
                conf=0.01,  # ë§¤ìš° ë‚®ì€ thresholdë¡œ ëª¨ë“  ì˜ˆì¸¡ í™•ì¸
                iou=0.5,
                max_det=300,
                device=device,
                verbose=False
            )[0]
            
            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
            if idx == 0:
                print(f"\n[ë””ë²„ê¹…] ì²« ë²ˆì§¸ ì´ë¯¸ì§€: {img_name_no_ext}")
                print(f"  - ê²€ì¶œëœ ë°•ìŠ¤ ê°œìˆ˜: {len(results.boxes)}")
                if len(results.boxes) > 0:
                    confidences = [float(box.conf) for box in results.boxes]
                    print(f"  - Confidence ë²”ìœ„: {min(confidences):.4f} ~ {max(confidences):.4f}")
                    print(f"  - í‰ê·  Confidence: {sum(confidences)/len(confidences):.4f}")
                    print(f"  - {conf_threshold} ì´ìƒì¸ ë°•ìŠ¤: {sum(1 for c in confidences if c >= conf_threshold)}ê°œ")
            
            # Confidence thresholdë¡œ í•„í„°ë§
            filtered_boxes = []
            for box in results.boxes:
                if float(box.conf) >= conf_threshold:
                    filtered_boxes.append(box)
            
            # ê²€ì¶œëœ ë°•ìŠ¤ê°€ ìµœì†Œ ê°œìˆ˜ ì´ìƒì¸ì§€ í™•ì¸
            if len(filtered_boxes) < min_boxes:
                skipped_count += 1
                if len(results.boxes) > 0:
                    max_confidences.append(max([float(box.conf) for box in results.boxes]))
                continue
            
            # JSON ì–´ë…¸í…Œì´ì…˜ ìƒì„± (confidence thresholdëŠ” í•¨ìˆ˜ ë‚´ì—ì„œ ì²´í¬)
            annotation_data = create_annotation_json(
                img_path, results, category_mapping, ann_id, conf_threshold
            )
            
            # ì–´ë…¸í…Œì´ì…˜ì´ ì‹¤ì œë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if len(annotation_data['annotations']) < min_boxes:
                skipped_count += 1
                continue
            
            # JSON íŒŒì¼ ì €ì¥ (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
            # íŒŒì¼ ì´ë¦„ì€ ì´ë¯¸ì§€ ì´ë¦„ê³¼ ë™ì¼í•˜ê²Œ
            json_filename = f"{img_name_no_ext}.json"
            json_path = os.path.join(output_dir, json_filename)
            
            # ê¸°ì¡´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë ¤ë©´ ë” ë³µì¡í•œ ë¡œì§ í•„ìš”
            # ì¼ë‹¨ ê°„ë‹¨í•˜ê²Œ output_dirì— ì €ì¥
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(annotation_data, f, ensure_ascii=False, indent=2)
            
            generated_count += 1
            ann_id += 1
            
        except Exception as e:
            print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ ({img_name_no_ext}): {e}")
            skipped_count += 1
            continue
    
    print(f"\n=== Pseudo-labeling ì™„ë£Œ ===")
    print(f"ìƒì„±ëœ ì–´ë…¸í…Œì´ì…˜: {generated_count}ê°œ")
    print(f"ê±´ë„ˆëœ€: {skipped_count}ê°œ")
    print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
    
    if max_confidences:
        print(f"\n[í†µê³„] ì˜ˆì¸¡ì´ ìˆì—ˆì§€ë§Œ threshold ë¯¸ë‹¬ì¸ ì´ë¯¸ì§€ë“¤:")
        print(f"  - í‰ê·  ìµœëŒ€ confidence: {sum(max_confidences)/len(max_confidences):.4f}")
        print(f"  - ìµœëŒ€ confidence: {max(max_confidences):.4f}")
        print(f"  - ìµœì†Œ confidence: {min(max_confidences):.4f}")
        print(f"  - {conf_threshold} ì´ìƒì¸ ì´ë¯¸ì§€: {sum(1 for c in max_confidences if c >= conf_threshold)}ê°œ")
        print(f"\nğŸ’¡ Tip: Confidence thresholdë¥¼ ë‚®ì¶”ë©´ ë” ë§ì€ ì–´ë…¸í…Œì´ì…˜ì´ ìƒì„±ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"   ì˜ˆ: python generate_pseudo_labels.py <model_path> 0.3")


if __name__ == "__main__":
    import sys
    
    # ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ì„¤ì •)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    BASE = os.path.dirname(script_dir)  # data_engineeringì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ = í”„ë¡œì íŠ¸ ë£¨íŠ¸
    
    TRAIN_IMG_DIR = os.path.join(BASE, "train_images")
    TRAIN_ANN_DIR = os.path.join(BASE, "train_annotations")
    CATEGORY_MAPPING = os.path.join(BASE, "category_mapping.json")
    
    # ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸ê°’: ìµœê·¼ í•™ìŠµëœ ëª¨ë¸)
    if len(sys.argv) > 1:
        MODEL_PATH = sys.argv[1]
    else:
        # ê¸°ë³¸ ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
        possible_models = [
            os.path.join(BASE, "pill_yolo_improved2", "weights", "best.pt"),
            os.path.join(BASE, "pill_yolo_improved", "weights", "best.pt"),
            os.path.join(BASE, "runs", "detect", "pill_yolo_improved2", "weights", "best.pt"),
        ]
        MODEL_PATH = None
        for path in possible_models:
            if os.path.exists(path):
                MODEL_PATH = path
                break
        
        if MODEL_PATH is None:
            print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ì‚¬ìš©ë²•: python generate_pseudo_labels.py <model_path>")
            print("ë˜ëŠ” ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµí•˜ì„¸ìš”.")
            sys.exit(1)
    
    # Confidence threshold ì„¤ì •
    conf_threshold = 0.5
    if len(sys.argv) > 2:
        conf_threshold = float(sys.argv[2])
    
    print("=== Pseudo-labeling ì‹œì‘ ===")
    print(f"ëª¨ë¸: {MODEL_PATH}")
    print(f"Train ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {TRAIN_IMG_DIR}")
    print(f"Train ì–´ë…¸í…Œì´ì…˜ ë””ë ‰í† ë¦¬: {TRAIN_ANN_DIR}")
    print(f"Confidence threshold: {conf_threshold}\n")
    
    generate_pseudo_labels(
        MODEL_PATH,
        BASE,
        TRAIN_IMG_DIR,
        TRAIN_ANN_DIR,
        CATEGORY_MAPPING,
        conf_threshold=conf_threshold,
        min_boxes=1  # ìµœì†Œ 1ê°œ ì´ìƒ ê²€ì¶œë˜ì–´ì•¼ ì €ì¥
    )

