from tqdm import tqdm
import torch
from torch.utils.data import DataLoader
from torch.optim import SGD
from torch.optim.lr_scheduler import StepLR

import torchvision
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor

from dataset import PillDataset  # ìœ„ì—ì„œ ë§Œë“  dataset.py


# -------------------------------------------------------
# 0) ë””ë°”ì´ìŠ¤ ì„ íƒ (M1 GPU(MPS) ìš°ì„  ì‚¬ìš©)
# -------------------------------------------------------
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸ”¥ Using Apple GPU (MPS)")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸ”¥ Using CUDA GPU")
else:
    device = torch.device("cpu")
    print("âš ï¸ Using CPU")


# -------------------------------------------------------
# 1) ëª¨ë¸ ìƒì„± í•¨ìˆ˜
# -------------------------------------------------------
def get_detection_model(num_classes: int):
    """
    num_classes: ì „ì²´ í´ë˜ìŠ¤ ê°œìˆ˜ (ë°°ê²½ í¬í•¨)
    """

    # ê°€ëŠ¥í•˜ë©´ ìµœì‹  ëª¨ë¸ ì‚¬ìš©
    try:
        model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(
            weights="DEFAULT"
        )
    except:
        # fallback
        model = torchvision.models.detection.fasterrcnn_resnet50_fpn(
            weights="DEFAULT"
        )

    # Head êµì²´ (í´ë˜ìŠ¤ ìˆ˜ ë§ì¶”ê¸°)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)

    return model


# -------------------------------------------------------
# 2) ë°ì´í„°ë¡œë”
# -------------------------------------------------------
def collate_fn(batch):
    return tuple(zip(*batch))


def get_loaders(root, batch_size=2, num_workers=0):
    # M1 ë©”ëª¨ë¦¬ ê³ ë ¤í•´ì„œ batch_size=2 ì¶”ì²œ
    train_dataset = PillDataset(root=root, split="train")
    val_dataset   = PillDataset(root=root, split="val")

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        collate_fn=collate_fn,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        collate_fn=collate_fn,
    )

    return train_loader, val_loader


# -------------------------------------------------------
# 3) í•™ìŠµ ë©”ì¸ í•¨ìˆ˜
# -------------------------------------------------------
def train():
    print("âœ¨ ì‚¬ìš© ë””ë°”ì´ìŠ¤:", device)

    # ë„¤ ë°ì´í„° ê²½ë¡œ
    root = "/Users/apple/Downloads/í”„ë¡œì íŠ¸1/ai06-level1-project"

    train_loader, val_loader = get_loaders(
        root=root,
        batch_size=2,   # M1ì´ë©´ 2 ì •ë„ê°€ ì•ˆì „
        num_workers=0
    )

    # ğŸ”¥ğŸ”¥ ì—¬ê¸°ë§Œ ë„¤ í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ê²Œ ìˆ˜ì •í•˜ë©´ ë¨!!
    NUM_CLASSES = 1 + 56   # ë°°ê²½ 1 + pill class 56ê°œ

    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model = get_detection_model(NUM_CLASSES)
    model.to(device)

    # Optimizer
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = SGD(
        params,
        lr=0.005,
        momentum=0.9,
        weight_decay=0.0005,
    )

    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

    num_epochs = 10

    # -------------------------------------------------------
    # ğŸ”¥ í•™ìŠµ ë£¨í”„
    # -------------------------------------------------------
    for epoch in range(num_epochs):
        model.train()
        epoch_loss = 0.0

        for images, targets in tqdm(
            train_loader,
            desc=f"Epoch {epoch+1}/{num_epochs}",
            ncols=100
        ):
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            images = [img.to(device) for img in images]
            targets = [
                {k: v.to(device) for k, v in t.items()}
                for t in targets
            ]

            loss_dict = model(images, targets)
            loss = sum(loss for loss in loss_dict.values())

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        scheduler.step()

        print(f"[{epoch+1}/{num_epochs}] ğŸ”¥ train loss: {epoch_loss:.4f}")

        # -------------------------------------------------------
        # ê°„ë‹¨í•œ validation (1ê°œ ë°°ì¹˜ë§Œ)
        # -------------------------------------------------------
        model.eval()
        with torch.no_grad():
            for images, targets in val_loader:
                images = [img.to(device) for img in images]
                outputs = model(images)

                print("ğŸ“Œ ì˜ˆì¸¡ boxes:", outputs[0]["boxes"].shape)
                print("ğŸ“Œ ì˜ˆì¸¡ labels ìƒ˜í”Œ:", outputs[0]["labels"][:5])
                break  # í•œ ë°°ì¹˜ë§Œ í™•ì¸
        model.train()

    # -------------------------------------------------------
    # ëª¨ë¸ ì €ì¥
    # -------------------------------------------------------
    torch.save(model.state_dict(), "fasterrcnn_pill_m1.pth")
    print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ fasterrcnn_pill_m1.pth")


# -------------------------------------------------------
# 4) ì‹¤í–‰
# -------------------------------------------------------
if __name__ == "__main__":
    train()
