"""
ê°œì„ ëœ YOLO ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì£¼ìš” ê°œì„  ì‚¬í•­:
1. ë” í° ëª¨ë¸: YOLOv8m â†’ YOLOv8l
2. ë” ë§ì€ epochs: 20 â†’ 50
3. ë” í° ì´ë¯¸ì§€ í¬ê¸°: 640 â†’ 800
4. ê°œì„ ëœ Augmentation
5. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
6. Early Stopping
7. TTA (Test Time Augmentation)
"""

import os
import json
import random
import re
import glob
import numpy as np
import torch
from ultralytics import YOLO
import pandas as pd
from pathlib import Path
import yaml

# OpenMP ì¤‘ë³µ ì´ˆê¸°í™” ë¬¸ì œ í•´ê²° (Windows)
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'


def set_seed(seed=42):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def train_improved_model(base_dir, yolo_dir, device=0, epochs=50, model_name="pill_yolo_improved"):
    """
    ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ YOLO ëª¨ë¸ í•™ìŠµ
    
    Args:
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        yolo_dir: YOLO ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        device: GPU ë””ë°”ì´ìŠ¤ ë²ˆí˜¸ ë˜ëŠ” 'cpu'
        epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
        model_name: ëª¨ë¸ ì´ë¦„ (ì €ì¥ í´ë”ëª…)
    
    Returns:
        í•™ìŠµ ê²°ê³¼ì™€ ëª¨ë¸ ê²½ë¡œë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    dataset_yaml = os.path.join(yolo_dir, "dataset.yaml")
    
    # dataset.yaml íŒŒì¼ì˜ pathë¥¼ ë™ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸
    if os.path.exists(dataset_yaml):
        with open(dataset_yaml, 'r', encoding='utf-8') as f:
            dataset_config = yaml.safe_load(f) or {}
        
        # pathë¥¼ yolo_dirì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì„¤ì •
        dataset_config['path'] = os.path.abspath(yolo_dir)
        
        # ì—…ë°ì´íŠ¸ëœ ì„¤ì •ì„ íŒŒì¼ì— ì €ì¥
        with open(dataset_yaml, 'w', encoding='utf-8') as f:
            yaml.dump(dataset_config, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
    
    # YOLOv8x ëª¨ë¸ ì‚¬ìš© (ê°€ì¥ í° ëª¨ë¸, ìµœê³  ì •í™•ë„)
    # GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ë©´ yolov8l.ptë¡œ ë³€ê²½
    try:
        model = YOLO("yolov8x.pt")
        print("âœ… YOLOv8x ëª¨ë¸ ì‚¬ìš© (ìµœê³  ì„±ëŠ¥)")
    except:
        model = YOLO("yolov8l.pt")
        print("âš ï¸ YOLOv8x ë¡œë“œ ì‹¤íŒ¨, YOLOv8l ì‚¬ìš©")
    
    # ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ
    results = model.train(
        data=dataset_yaml,
        
        # ëª¨ë¸ ì„¤ì •
        epochs=epochs,              # ê¸°ë³¸ê°’ ì‚¬ìš© (ë” ì¶©ë¶„í•œ í•™ìŠµ)
        imgsz=1024,                # 800 â†’ 1024 (ë” í° ì´ë¯¸ì§€ë¡œ ì‘ì€ ê°ì²´ ê²€ì¶œ ê°œì„ )
        batch=4,                    # 8 â†’ 4 (ë” í° ì´ë¯¸ì§€ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì ˆì•½)
        device=device,
        name=model_name,
        project=base_dir,          # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ëª…ì‹œì ìœ¼ë¡œ ì§€ì • (ê²½ë¡œ ë¬¸ì œ í•´ê²°)
        
        # í•™ìŠµë¥  ì„¤ì • (Cosine Annealing)
        lr0=0.0005,                # 0.001 â†’ 0.0005 (ë” ì•ˆì •ì ì¸ í•™ìŠµ)
        lrf=0.01,                  # ìµœì¢… í•™ìŠµë¥  ë¹„ìœ¨
        momentum=0.937,
        weight_decay=0.0005,
        warmup_epochs=5.0,         # 3.0 â†’ 5.0 (ë” ê¸´ warmup)
        warmup_momentum=0.8,
        warmup_bias_lr=0.1,
        cos_lr=True,               # Cosine learning rate scheduler í™œì„±í™”
        
        # Augmentation (ì•½ ì´ë¯¸ì§€ì— ìµœì í™”, ë” ê°•í™”)
        hsv_h=0.02,                # 0.015 â†’ 0.02 (ìƒ‰ì¡° ë³€í™” ì¦ê°€)
        hsv_s=0.7,                 # ì±„ë„ ë³€í™” (ì•½ì˜ ìƒ‰ìƒ ë‹¤ì–‘ì„± ë°˜ì˜)
        hsv_v=0.4,                 # ëª…ë„ ë³€í™”
        degrees=15,                 # 10 â†’ 15 (íšŒì „ ê°ë„ ì¦ê°€)
        translate=0.15,            # 0.1 â†’ 0.15 (ì´ë™ ì¦ê°€)
        scale=0.6,                 # 0.5 â†’ 0.6 (í¬ê¸° ë³€í™” ë²”ìœ„ ì¦ê°€)
        shear=8,                   # 5 â†’ 8 (ì „ë‹¨ ë³€í™˜ ì¦ê°€)
        perspective=0.0002,        # 0.0001 â†’ 0.0002 (ì›ê·¼ ë³€í™˜ ì¦ê°€)
        fliplr=0.5,                # ì¢Œìš° ë°˜ì „
        flipud=0.0,                # ìƒí•˜ ë°˜ì „ (ì•½ ì´ë¯¸ì§€ì—ëŠ” ë¶€ì ì ˆ)
        mosaic=1.0,                # Mosaic augmentation
        mixup=0.15,                # 0.1 â†’ 0.15 (Mixup augmentation ì¦ê°€)
        copy_paste=0.15,           # 0.1 â†’ 0.15 (Copy-paste augmentation ì¦ê°€)
        erasing=0.4,               # Random erasing ì¶”ê°€
        auto_augment="randaugment", # Auto augmentation í™œì„±í™”
        
        # í•™ìŠµ ì„¤ì •
        patience=20,               # 15 â†’ 20 (Early stopping patience ì¦ê°€)
        save=True,
        save_period=5,             # 10 â†’ 5 (ë” ìì£¼ ì²´í¬í¬ì¸íŠ¸ ì €ì¥)
        val=True,
        plots=True,
        close_mosaic=10,           # ë§ˆì§€ë§‰ 10 epochì—ì„œ mosaic ë¹„í™œì„±í™”
        
        # ì¬í˜„ì„±
        seed=42,
        deterministic=True,
        
        # ê¸°íƒ€
        workers=0,                 # Windows ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ í•´ê²° (0 = ë©”ì¸ í”„ë¡œì„¸ìŠ¤ë§Œ ì‚¬ìš©)
        amp=True,                  # Automatic Mixed Precision (ì†ë„ í–¥ìƒ)
        fraction=1.0,              # ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
        profile=False,
        freeze=None,
        multi_scale=False,        # Multi-scale training (ë©”ëª¨ë¦¬ ì ˆì•½)
        
        # Loss ê°€ì¤‘ì¹˜ (ë” ì •êµí•œ íŠœë‹)
        box=7.5,                   # Box loss ê°€ì¤‘ì¹˜
        cls=0.5,                   # Classification loss ê°€ì¤‘ì¹˜
        dfl=1.5,                   # Distribution Focal Loss ê°€ì¤‘ì¹˜
        
        # NMS ì„¤ì •
        iou=0.7,                   # NMS IoU threshold
        conf=0.25,                 # Confidence threshold
        max_det=300,               # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
        
        # ì¶”ê°€ ìµœì í™”
        optimizer="AdamW",         # SGD â†’ AdamW (ë” ë‚˜ì€ ìˆ˜ë ´)
        nbs=64,                    # Nominal batch size
        overlap_mask=True,         # Overlap mask í™œì„±í™”
    )
    
    # ëª¨ë¸ ê²½ë¡œ ë°˜í™˜ (YOLOê°€ ì‹¤ì œë¡œ ì €ì¥í•œ ê²½ë¡œ ì‚¬ìš©)
    # YOLOëŠ” project íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ í™•ì¸í•˜ì—¬ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
    
    # results ê°ì²´ì—ì„œ ì‹¤ì œ ì €ì¥ ê²½ë¡œ í™•ì¸
    if hasattr(results, "save_dir") and results.save_dir:
        # YOLOê°€ ë°˜í™˜í•œ ì‹¤ì œ ì €ì¥ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        model_path = os.path.join(results.save_dir, "weights", "best.pt")
        if os.path.exists(model_path):
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬ (results.save_dir): {model_path}")
            return {
                "results": results,
                "model_path": model_path,
                "model_name": model_name
            }
    
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
    possible_paths = [
        os.path.join(base_dir, "runs", "detect", model_name, "weights", "best.pt"),
        os.path.join(os.getcwd(), "runs", "detect", model_name, "weights", "best.pt"),
    ]
    
    # ëª¨ë¸ ì´ë¦„ ë³€í˜•ë„ í™•ì¸ (pill_yolo_improved2 ë“±)
    model_name_variants = [model_name, f"{model_name}2", f"{model_name}_2"]
    for variant in model_name_variants:
        possible_paths.extend([
            os.path.join(base_dir, "runs", "detect", variant, "weights", "best.pt"),
            os.path.join(os.getcwd(), "runs", "detect", variant, "weights", "best.pt"),
        ])
    
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œë„ ê²€ìƒ‰ (D:\AI \part2_kaggle ê°™ì€ ê²½ìš° ëŒ€ë¹„)
    parent_dirs = [
        os.path.dirname(base_dir),  # base_dirì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
        os.path.dirname(os.getcwd()),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
    ]
    for parent_dir in parent_dirs:
        if parent_dir and os.path.exists(parent_dir):
            for variant in model_name_variants:
                possible_paths.append(
                    os.path.join(parent_dir, "runs", "detect", variant, "weights", "best.pt")
                )
    
    model_path = None
    for path in possible_paths:
        if os.path.exists(path):
            model_path = path
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_path}")
            break
    
    if model_path is None:
        # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (ë‚˜ì¤‘ì— ì—ëŸ¬ ì²˜ë¦¬)
        model_path = os.path.join(base_dir, "runs", "detect", model_name, "weights", "best.pt")
        print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì˜ˆìƒ ê²½ë¡œ: {model_path}")
        print(f"   ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:")
        for path in possible_paths[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"   - {path}")
    
    return {
        "results": results,
        "model_path": model_path,
        "model_name": model_name
    }


def validate_model(model_path, dataset_yaml, device=0):
    """ëª¨ë¸ ê²€ì¦"""
    model = YOLO(model_path)
    
    metrics = model.val(
        data=dataset_yaml,
        imgsz=1024,                # 800 â†’ 1024 (í•™ìŠµê³¼ ë™ì¼í•œ í¬ê¸°)
        conf=0.25,
        iou=0.7,
        device=device,
    )
    
    print(f"\n=== ê²€ì¦ ê²°ê³¼ ===")
    print(f"mAP50: {metrics.box.map50:.4f}")
    print(f"mAP50-95: {metrics.box.map:.4f}")
    print(f"Precision: {metrics.box.mp:.4f}")
    print(f"Recall: {metrics.box.mr:.4f}")
    
    return metrics


def save_training_summary(model_path, metrics, output_path):
    """
    í•™ìŠµ ê²°ê³¼ ìš”ì•½ì„ CSVë¡œ ì €ì¥
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ
        metrics: ê²€ì¦ ë©”íŠ¸ë¦­
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    summary = {
        "model_path": [model_path],
        "mAP50": [metrics.box.map50],
        "mAP50-95": [metrics.box.map],
        "Precision": [metrics.box.mp],
        "Recall": [metrics.box.mr],
    }
    
    df_summary = pd.DataFrame(summary)
    df_summary.to_csv(output_path, index=False)
    print(f"í•™ìŠµ ê²°ê³¼ ìš”ì•½ ì €ì¥: {output_path}")


def predict_with_tta(model, img_path, conf_threshold=0.5, iou_threshold=0.5, max_det=300):
    """
    Test Time Augmentationì„ ì‚¬ìš©í•œ ì¶”ë¡ 
    
    Args:
        model: YOLO ëª¨ë¸
        img_path: ì´ë¯¸ì§€ ê²½ë¡œ
        conf_threshold: Confidence threshold
        iou_threshold: NMS IoU threshold
        max_det: ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
    
    Returns:
        ì¶”ë¡  ê²°ê³¼
    """
    results = model.predict(
        img_path,
        imgsz=1024,                # 800 â†’ 1024 (í•™ìŠµê³¼ ë™ì¼í•œ í¬ê¸°)
        conf=conf_threshold,
        iou=iou_threshold,
        max_det=max_det,
        augment=True,  # TTA í™œì„±í™”
        verbose=False
    )
    
    return results[0]


def generate_submission(model_path, test_img_dir, category_mapping_path, 
                       output_path, conf_threshold=0.5, use_tta=False, iou_threshold=0.5, max_det=300):
    """
    Kaggle ì œì¶œìš© CSV íŒŒì¼ ìƒì„±
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        test_img_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        category_mapping_path: Category mapping JSON íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
        conf_threshold: Confidence threshold (ê¸°ë³¸ê°’: 0.5, ë” ë†’ì€ ì •í™•ë„)
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, TTAëŠ” ë•Œë•Œë¡œ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦¼)
        iou_threshold: NMS IoU threshold (ê¸°ë³¸ê°’: 0.5, ë” ì—„ê²©í•œ í•„í„°ë§)
        max_det: ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
    """
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # Category mapping ë¡œë“œ
    with open(category_mapping_path, "r") as f:
        mapping = json.load(f)
    idx2cat = {int(k): v for k, v in mapping["idx2cat"].items()}
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = []
    ann_id = 1
    
    test_images = sorted([f for f in os.listdir(test_img_dir) if f.endswith(".png")])
    total_images = len(test_images)
    
    print(f"ì´ {total_images}ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
    print(f"ì„¤ì •: conf_threshold={conf_threshold}, iou_threshold={iou_threshold}, use_tta={use_tta}")
    
    for idx, img_name in enumerate(test_images, 1):
        if idx % 10 == 0 or idx == total_images:
            print(f"ì§„í–‰ ì¤‘... ({idx}/{total_images} ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ)")
        img_id = int(img_name.replace(".png", ""))
        img_path = os.path.join(test_img_dir, img_name)
        
        # ì¶”ë¡  (ë” ì—„ê²©í•œ ì„¤ì •)
        if use_tta:
            results = predict_with_tta(model, img_path, conf_threshold, iou_threshold, max_det)
        else:
            results = model.predict(
                img_path,
                imgsz=1024,              # 800 â†’ 1024 (í•™ìŠµê³¼ ë™ì¼í•œ í¬ê¸°)
                conf=conf_threshold,      # Confidence threshold
                iou=iou_threshold,        # NMS IoU threshold
                max_det=max_det,          # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
                verbose=False
            )[0]
        
        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì—ì„œ ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
        if idx == 1:
            print(f"\n[ë””ë²„ê¹…] ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"  - ê²€ì¶œëœ ë°•ìŠ¤ ê°œìˆ˜: {len(results.boxes)}")
            if len(results.boxes) > 0:
                print(f"  - ì²« ë²ˆì§¸ ë°•ìŠ¤ confidence: {float(results.boxes[0].conf):.4f}")
                print(f"  - ì²« ë²ˆì§¸ ë°•ìŠ¤ class: {int(results.boxes[0].cls)}")
        
        # Score ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ í•„í„°ë§ (confidenceê°€ ë‚®ì€ ì˜ˆì¸¡ ì œê±°)
        for box in results.boxes:
            cls = int(box.cls)
            score = float(box.conf)
            
            # Confidenceê°€ thresholdë³´ë‹¤ ë‚®ìœ¼ë©´ ì œì™¸
            if score < conf_threshold:
                continue
                
            orig_cid = idx2cat[cls]
            
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            w = x2 - x1
            h = y2 - y1
            
            # Bounding box ìœ íš¨ì„± ê²€ì‚¬ (ë„ˆë¬´ ì‘ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° ì œì™¸)
            if w <= 0 or h <= 0 or x1 < 0 or y1 < 0:
                continue
            
            submission.append([
                ann_id, img_id, orig_cid,
                float(x1), float(y1), float(w), float(h), score
            ])
            ann_id += 1
    
    # CSV ì €ì¥
    df = pd.DataFrame(submission, columns=[
        "annotation_id", "image_id", "category_id",
        "bbox_x", "bbox_y", "bbox_w", "bbox_h", "score"
    ])
    
    df.to_csv(output_path, index=False)
    print(f"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ì´ ì˜ˆì¸¡ ê°œìˆ˜: {len(submission)}")
    
    return df


def extract_model_name_from_path(model_path):
    """
    ëª¨ë¸ ê²½ë¡œì—ì„œ ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ
    
    Args:
        model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
    
    Returns:
        ëª¨ë¸ ì´ë¦„
    """
    # ê²½ë¡œë¥¼ ì •ê·œí™”
    normalized_path = model_path.replace("\\", "/")
    path_parts = normalized_path.split("/")
    
    # pill_yolo_improved* íŒ¨í„´ ì°¾ê¸°
    for part in path_parts:
        if "pill_yolo_improved" in part:
            return part
    
    # runs/detect/ëª¨ë¸ì´ë¦„/weights/best.pt í˜•ì‹
    if "runs" in path_parts and "detect" in path_parts:
        detect_idx = path_parts.index("detect")
        if detect_idx + 1 < len(path_parts):
            return path_parts[detect_idx + 1]
    
    # ê¸°ë³¸ê°’
    return "pill_yolo_improved"


def find_existing_model(base_dir, model_name="pill_yolo_improved"):
    """
    ê¸°ì¡´ì— í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ê¸° (ê°€ì¥ ìµœê·¼ ëª¨ë¸ ìš°ì„ )
    
    Args:
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        model_name: ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’, ëª¨ë“  ëª¨ë¸ ê²€ìƒ‰)
    
    Returns:
        ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” None
    """
    found_models = []
    
    # ëª¨ë“  ê°€ëŠ¥í•œ ê²½ë¡œì—ì„œ ëª¨ë¸ ê²€ìƒ‰
    search_dirs = [
        base_dir,
        os.getcwd(),
        os.path.dirname(base_dir),
        os.path.dirname(os.getcwd()),
    ]
    
    for search_dir in search_dirs:
        if not search_dir or not os.path.exists(search_dir):
            continue
        
        # runs/detect/*/weights/best.pt íŒ¨í„´ ê²€ìƒ‰
        runs_detect_pattern = os.path.join(search_dir, "runs", "detect", "*", "weights", "best.pt")
        found_models.extend(glob.glob(runs_detect_pattern))
        
        # ì§ì ‘ ëª¨ë¸ ë””ë ‰í† ë¦¬ íŒ¨í„´ ê²€ìƒ‰ (pill_yolo_improved*/weights/best.pt)
        model_pattern = os.path.join(search_dir, "pill_yolo_improved*", "weights", "best.pt")
        found_models.extend(glob.glob(model_pattern))
    
    if not found_models:
        return None
    
    # ì¤‘ë³µ ì œê±° ë° ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
    found_models = list(set([f for f in found_models if os.path.exists(f)]))
    
    if not found_models:
        return None
    
    # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ê°€ì¥ ìµœê·¼ ê²ƒ ìš°ì„ )
    found_models.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    
    # ê°€ì¥ ìµœê·¼ ëª¨ë¸ ë°˜í™˜
    latest_model = found_models[0]
    print(f"ğŸ“Œ ë°œê²¬ëœ ëª¨ë¸ ê°œìˆ˜: {len(found_models)}ê°œ")
    print(f"ğŸ“Œ ê°€ì¥ ìµœê·¼ ëª¨ë¸ ì„ íƒ: {os.path.basename(os.path.dirname(os.path.dirname(latest_model)))}")
    
    return latest_model


if __name__ == "__main__":
    import sys
    
    # ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë™ì ìœ¼ë¡œ ì„¤ì •)
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬: model_architecture/
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸: ìƒìœ„ ë””ë ‰í† ë¦¬ 1ê°œ
    script_dir = os.path.dirname(os.path.abspath(__file__))
    BASE = os.path.dirname(script_dir)  # model_architectureì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ = í”„ë¡œì íŠ¸ ë£¨íŠ¸
    
    # ë°ì´í„°ì…‹ ìš°ì„ ìˆœìœ„: ë³‘í•©ëœ ë°ì´í„°ì…‹ > yolo_dataset > yolo_multiclass
    yolo_merged_path = os.path.join(BASE, "yolo_dataset_merged")
    yolo_dataset_path = os.path.join(BASE, "yolo_dataset")
    yolo_multiclass_path = os.path.join(BASE, "yolo_multiclass")
    
    if os.path.exists(yolo_merged_path) and os.path.exists(os.path.join(yolo_merged_path, "images", "train")):
        YOLO_DIR = yolo_merged_path
        print("âœ… ë³‘í•©ëœ ë°ì´í„°ì…‹(yolo_dataset_merged) ì‚¬ìš©")
        print(f"   - Train: {len([f for f in os.listdir(os.path.join(yolo_merged_path, 'images', 'train')) if f.endswith(('.png', '.jpg', '.jpeg'))])}ê°œ")
        print(f"   - Val: {len([f for f in os.listdir(os.path.join(yolo_merged_path, 'images', 'val')) if f.endswith(('.png', '.jpg', '.jpeg'))]) if os.path.exists(os.path.join(yolo_merged_path, 'images', 'val')) else 0}ê°œ")
    elif os.path.exists(yolo_dataset_path) and os.path.exists(os.path.join(yolo_dataset_path, "dataset.yaml")):
        YOLO_DIR = yolo_dataset_path
        print("âœ… ìˆ˜ë™ ë¼ë²¨ë§ëœ yolo_dataset ì‚¬ìš©")
    else:
        YOLO_DIR = yolo_multiclass_path
        print("âš ï¸ yolo_datasetì„ ì°¾ì„ ìˆ˜ ì—†ì–´ yolo_multiclass ì‚¬ìš©")
    
    TEST_IMG_DIR = os.path.join(BASE, "test_images")
    CATEGORY_MAPPING = os.path.join(BASE, "category_mapping.json")
    
    # ê²½ë¡œ í™•ì¸ ì¶œë ¥
    print(f"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ: {BASE}")
    print(f"ğŸ“ YOLO ë°ì´í„°ì…‹ ê²½ë¡œ: {YOLO_DIR}")
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ: {TEST_IMG_DIR}")
    print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ íŒŒì¼: {CATEGORY_MAPPING}")
    
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸ (--skip-training ë˜ëŠ” --inference-only)
    skip_training = "--skip-training" in sys.argv or "--inference-only" in sys.argv
    # --force-train ì˜µì…˜ì´ ìˆìœ¼ë©´ ê°•ì œë¡œ í•™ìŠµ
    force_train = "--force-train" in sys.argv
    
    # ì‹œë“œ ê³ ì •
    set_seed(42)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {'GPU' if device == 0 else 'CPU'}")
    
    # ê¸°ì¡´ ëª¨ë¸ ì°¾ê¸°
    existing_model = find_existing_model(BASE)
    
    # ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©
    if force_train:
        print("\nğŸ”„ --force-train ì˜µì…˜: ê°•ì œë¡œ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        skip_training = False
    elif skip_training and existing_model:
        # --skip-training ì˜µì…˜ì´ ìˆê³  ê¸°ì¡´ ëª¨ë¸ì´ ìˆëŠ” ê²½ìš°ë§Œ ì‚¬ìš©
        print(f"\nâœ… ê¸°ì¡´ ëª¨ë¸ ë°œê²¬: {existing_model}")
        print("--skip-training ì˜µì…˜ì— ë”°ë¼ ê¸°ì¡´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        best_model_path = existing_model
        skip_training = True
        # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ (ê²½ë¡œì—ì„œ ìë™ ì¶”ì¶œ)
        model_name = extract_model_name_from_path(best_model_path)
    elif existing_model:
        # ê¸°ì¡´ ëª¨ë¸ì´ ìˆì§€ë§Œ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²½ê³ 
        print(f"\nâš ï¸ ê¸°ì¡´ ëª¨ë¸ ë°œê²¬: {existing_model}")
        print("âš ï¸ ê²½ê³ : ì´ ëª¨ë¸ì€ ë ˆì´ë¸”ì´ ê±°ì˜ ì—†ëŠ” ìƒíƒœì—ì„œ í•™ìŠµë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("âš ï¸ ìƒˆë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. (--force-train ì˜µì…˜ ì‚¬ìš©)")
        print("\nğŸ’¡ ê¸°ë³¸ì ìœ¼ë¡œ ìƒˆë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        print("   (ê¸°ì¡´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ --skip-training ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”)")
        skip_training = False
    elif skip_training:
        # --skip-training ì˜µì…˜ì´ ìˆì§€ë§Œ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°
        print("âš ï¸ --skip-training ì˜µì…˜ì´ ìˆì§€ë§Œ ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        skip_training = False
    else:
        # ê¸°ì¡´ ëª¨ë¸ë„ ì—†ê³  ì˜µì…˜ë„ ì—†ëŠ” ê²½ìš° â†’ í•™ìŠµ ì‹œì‘
        print("\nğŸ’¡ ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        skip_training = False
    
    if not skip_training:
        # 1. ëª¨ë¸ í•™ìŠµ
        print("\n=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
        train_result = train_improved_model(BASE, YOLO_DIR, device=device, epochs=50)
        best_model_path = train_result["model_path"]
        model_name = train_result["model_name"]
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {best_model_path}")
        
        # 2. ê²€ì¦
        print("\n=== ëª¨ë¸ ê²€ì¦ ===")
        if os.path.exists(best_model_path):
            metrics = validate_model(best_model_path, os.path.join(YOLO_DIR, "dataset.yaml"), device)
            
            # í•™ìŠµ ê²°ê³¼ ìš”ì•½ ì €ì¥
            summary_path = os.path.join(BASE, f"training_summary_{model_name}.csv")
            save_training_summary(best_model_path, metrics, summary_path)
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {best_model_path}")
            print("í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            exit(1)
    else:
        # ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œ ê²€ì¦ì€ ì„ íƒì‚¬í•­
        print("\nğŸ’¡ ê¸°ì¡´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²€ì¦ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"   ëª¨ë¸ ê²½ë¡œ: {best_model_path}")
    
    # 3. ì œì¶œ íŒŒì¼ ìƒì„±
    print("\n=== ì œì¶œ íŒŒì¼ ìƒì„± ===")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(TEST_IMG_DIR):
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {TEST_IMG_DIR}")
        print("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        # ì œì¶œ íŒŒì¼ ê²½ë¡œ (ë²„ì „ ë²ˆí˜¸ ìë™ ì¶”ê°€)
        base_filename = f"kaggle_submission_{model_name}"
        
        # ê¸°ì¡´ íŒŒì¼ì—ì„œ ìµœëŒ€ ë²„ì „ ë²ˆí˜¸ ì°¾ê¸° (ë‘ ê°€ì§€ íŒ¨í„´ ëª¨ë‘ í™•ì¸)
        pattern1 = os.path.join(BASE, f"{base_filename}_ver*.csv")
        pattern2 = os.path.join(BASE, "kaggle_submission_ver*.csv")
        existing_files = glob.glob(pattern1) + glob.glob(pattern2)
        
        # ver ë’¤ì˜ ìˆ«ì ì¶”ì¶œ
        max_version = 0
        for file in existing_files:
            filename = os.path.basename(file)
            # kaggle_submission_pill_yolo_improved_ver1.csv ë˜ëŠ” kaggle_submission_ver2.csv í˜•ì‹ì—ì„œ ìˆ«ì ì¶”ì¶œ
            match = re.search(r'_ver(\d+)\.csv$', filename)
            if match:
                version = int(match.group(1))
                max_version = max(max_version, version)
        
        # ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸
        next_version = max_version + 1
        output_path = os.path.join(BASE, f"{base_filename}_ver{next_version}.csv")
        
        print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {TEST_IMG_DIR}")
        print(f"ì¶œë ¥ íŒŒì¼: {output_path} (ë²„ì „ {next_version})")
        
        try:
            # ê°œì„ ëœ íŒŒë¼ë¯¸í„°ë¡œ ì œì¶œ íŒŒì¼ ìƒì„±
            # ê¸°ì¡´ ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ confidence thresholdë¥¼ ë‚®ì¶¤
            df = generate_submission(
                best_model_path,
                TEST_IMG_DIR,
                CATEGORY_MAPPING,
                output_path,
                conf_threshold=0.25,     # 0.5 â†’ 0.25 (ë‚®ì¶°ì„œ ì˜ˆì¸¡ í™•ì¸)
                use_tta=False,           # TTA ë¹„í™œì„±í™”
                iou_threshold=0.5,      # NMS IoU threshold
                max_det=300             # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
            )
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“Š ì œì¶œ íŒŒì¼ ìš”ì•½:")
            print(f"  - ì´ ì˜ˆì¸¡ ê°œìˆ˜: {len(df)}")
            print(f"  - ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜: {df['image_id'].nunique()}")
            print(f"  - ê³ ìœ  ì¹´í…Œê³ ë¦¬ ìˆ˜: {df['category_id'].nunique()}")
            print(f"  - í‰ê·  Confidence: {df['score'].mean():.4f}")
            print(f"  - ìµœì†Œ Confidence: {df['score'].min():.4f}")
            print(f"  - ìµœëŒ€ Confidence: {df['score'].max():.4f}")
            
        except Exception as e:
            print(f"âŒ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*50)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("="*50)

