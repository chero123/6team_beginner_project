"""
ê°œì„ ëœ YOLO ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì£¼ìš” ê°œì„  ì‚¬í•­:
1. ë” í° ëª¨ë¸: YOLOv8m â†’ YOLOv8l
2. ë” ë§ì€ epochs: 20 â†’ 50
3. ë” í° ì´ë¯¸ì§€ í¬ê¸°: 640 â†’ 800
4. ê°œì„ ëœ Augmentation
5. í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
6. Early Stopping
7. TTA (Test Time Augmentation)
"""

import os
import json
import random
import numpy as np
import torch
from ultralytics import YOLO
import pandas as pd
from pathlib import Path

# OpenMP ì¤‘ë³µ ì´ˆê¸°í™” ë¬¸ì œ í•´ê²° (Windows)
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'


def set_seed(seed=42):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False


def train_improved_model(base_dir, yolo_dir, device=0, epochs=50, model_name="pill_yolo_improved"):
    """
    ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ YOLO ëª¨ë¸ í•™ìŠµ
    
    Args:
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        yolo_dir: YOLO ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
        device: GPU ë””ë°”ì´ìŠ¤ ë²ˆí˜¸ ë˜ëŠ” 'cpu'
        epochs: í•™ìŠµ ì—í¬í¬ ìˆ˜
        model_name: ëª¨ë¸ ì´ë¦„ (ì €ì¥ í´ë”ëª…)
    
    Returns:
        í•™ìŠµ ê²°ê³¼ì™€ ëª¨ë¸ ê²½ë¡œë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    dataset_yaml = os.path.join(yolo_dir, "dataset.yaml")
    
    # YOLOv8l ëª¨ë¸ ì‚¬ìš© (ë” í° ëª¨ë¸, ë” ë†’ì€ ì •í™•ë„)
    model = YOLO("yolov8l.pt")
    
    # ê°œì„ ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµ
    results = model.train(
        data=dataset_yaml,
        
        # ëª¨ë¸ ì„¤ì •
        epochs=epochs,              # 20 â†’ 50 (ë” ì¶©ë¶„í•œ í•™ìŠµ)
        imgsz=800,                 # 640 â†’ 800 (ì‘ì€ ê°ì²´ ê²€ì¶œ ê°œì„ )
        batch=8,                   # GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
        device=device,
        name=model_name,
        project=base_dir,          # í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ëª…ì‹œì ìœ¼ë¡œ ì§€ì • (ê²½ë¡œ ë¬¸ì œ í•´ê²°)
        
        # í•™ìŠµë¥  ì„¤ì •
        lr0=0.001,                 # ì´ˆê¸° í•™ìŠµë¥  (ë” ë‚®ê²Œ ì‹œì‘)
        lrf=0.01,                  # ìµœì¢… í•™ìŠµë¥  ë¹„ìœ¨
        momentum=0.937,
        weight_decay=0.0005,
        warmup_epochs=3.0,
        warmup_momentum=0.8,
        warmup_bias_lr=0.1,
        
        # Augmentation (ì•½ ì´ë¯¸ì§€ì— ìµœì í™”)
        hsv_h=0.015,               # ìƒ‰ì¡° ë³€í™”
        hsv_s=0.7,                 # ì±„ë„ ë³€í™” (ì•½ì˜ ìƒ‰ìƒ ë‹¤ì–‘ì„± ë°˜ì˜)
        hsv_v=0.4,                 # ëª…ë„ ë³€í™”
        degrees=10,                 # íšŒì „ ê°ë„ (5 â†’ 10)
        translate=0.1,             # ì´ë™ (0.05 â†’ 0.1)
        scale=0.5,                 # í¬ê¸° ë³€í™”
        shear=5,                   # ì „ë‹¨ ë³€í™˜ ì¶”ê°€
        perspective=0.0001,         # ì›ê·¼ ë³€í™˜ ì¶”ê°€
        fliplr=0.5,                # ì¢Œìš° ë°˜ì „
        flipud=0.0,                # ìƒí•˜ ë°˜ì „ (ì•½ ì´ë¯¸ì§€ì—ëŠ” ë¶€ì ì ˆ)
        mosaic=1.0,                # Mosaic augmentation (0.7 â†’ 1.0)
        mixup=0.1,                 # Mixup augmentation (0.05 â†’ 0.1)
        copy_paste=0.1,            # Copy-paste augmentation ì¶”ê°€
        
        # í•™ìŠµ ì„¤ì •
        patience=15,               # Early stopping patience
        save=True,
        save_period=10,            # 10 epochë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        val=True,
        plots=True,
        
        # ì¬í˜„ì„±
        seed=42,
        deterministic=True,
        
        # ê¸°íƒ€
        workers=0,                 # Windows ë©€í‹°í”„ë¡œì„¸ì‹± ë¬¸ì œ í•´ê²° (0 = ë©”ì¸ í”„ë¡œì„¸ìŠ¤ë§Œ ì‚¬ìš©)
        amp=True,                  # Automatic Mixed Precision (ì†ë„ í–¥ìƒ)
        fraction=1.0,              # ì „ì²´ ë°ì´í„°ì…‹ ì‚¬ìš©
        profile=False,
        freeze=None,
        
        # Loss ê°€ì¤‘ì¹˜
        box=7.5,                   # Box loss ê°€ì¤‘ì¹˜
        cls=0.5,                   # Classification loss ê°€ì¤‘ì¹˜
        dfl=1.5,                   # Distribution Focal Loss ê°€ì¤‘ì¹˜
        
        # NMS ì„¤ì •
        iou=0.7,                   # NMS IoU threshold
        conf=0.25,                 # Confidence threshold
        max_det=300,               # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
    )
    
    # ëª¨ë¸ ê²½ë¡œ ë°˜í™˜ (YOLOê°€ ì‹¤ì œë¡œ ì €ì¥í•œ ê²½ë¡œ ì‚¬ìš©)
    # YOLOëŠ” project íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ í™•ì¸í•˜ì—¬ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
    
    # results ê°ì²´ì—ì„œ ì‹¤ì œ ì €ì¥ ê²½ë¡œ í™•ì¸
    if hasattr(results, "save_dir") and results.save_dir:
        # YOLOê°€ ë°˜í™˜í•œ ì‹¤ì œ ì €ì¥ ë””ë ‰í† ë¦¬ ì‚¬ìš©
        model_path = os.path.join(results.save_dir, "weights", "best.pt")
        if os.path.exists(model_path):
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬ (results.save_dir): {model_path}")
            return {
                "results": results,
                "model_path": model_path,
                "model_name": model_name
            }
    
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
    possible_paths = [
        os.path.join(base_dir, "runs", "detect", model_name, "weights", "best.pt"),
        os.path.join(os.getcwd(), "runs", "detect", model_name, "weights", "best.pt"),
    ]
    
    # ëª¨ë¸ ì´ë¦„ ë³€í˜•ë„ í™•ì¸ (pill_yolo_improved2 ë“±)
    model_name_variants = [model_name, f"{model_name}2", f"{model_name}_2"]
    for variant in model_name_variants:
        possible_paths.extend([
            os.path.join(base_dir, "runs", "detect", variant, "weights", "best.pt"),
            os.path.join(os.getcwd(), "runs", "detect", variant, "weights", "best.pt"),
        ])
    
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œë„ ê²€ìƒ‰ (D:\AI \part2_kaggle ê°™ì€ ê²½ìš° ëŒ€ë¹„)
    parent_dirs = [
        os.path.dirname(base_dir),  # base_dirì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
        os.path.dirname(os.getcwd()),  # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬
    ]
    for parent_dir in parent_dirs:
        if parent_dir and os.path.exists(parent_dir):
            for variant in model_name_variants:
                possible_paths.append(
                    os.path.join(parent_dir, "runs", "detect", variant, "weights", "best.pt")
                )
    
    model_path = None
    for path in possible_paths:
        if os.path.exists(path):
            model_path = path
            print(f"âœ… ëª¨ë¸ íŒŒì¼ ë°œê²¬: {model_path}")
            break
    
    if model_path is None:
        # ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (ë‚˜ì¤‘ì— ì—ëŸ¬ ì²˜ë¦¬)
        model_path = os.path.join(base_dir, "runs", "detect", model_name, "weights", "best.pt")
        print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì˜ˆìƒ ê²½ë¡œ: {model_path}")
        print(f"   ë‹¤ìŒ ê²½ë¡œë“¤ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:")
        for path in possible_paths[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"   - {path}")
    
    return {
        "results": results,
        "model_path": model_path,
        "model_name": model_name
    }


def validate_model(model_path, dataset_yaml, device=0):
    """ëª¨ë¸ ê²€ì¦"""
    model = YOLO(model_path)
    
    metrics = model.val(
        data=dataset_yaml,
        imgsz=800,
        conf=0.25,
        iou=0.7,
        device=device,
    )
    
    print(f"\n=== ê²€ì¦ ê²°ê³¼ ===")
    print(f"mAP50: {metrics.box.map50:.4f}")
    print(f"mAP50-95: {metrics.box.map:.4f}")
    print(f"Precision: {metrics.box.mp:.4f}")
    print(f"Recall: {metrics.box.mr:.4f}")
    
    return metrics


def save_training_summary(model_path, metrics, output_path):
    """
    í•™ìŠµ ê²°ê³¼ ìš”ì•½ì„ CSVë¡œ ì €ì¥
    
    Args:
        model_path: ëª¨ë¸ ê²½ë¡œ
        metrics: ê²€ì¦ ë©”íŠ¸ë¦­
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    """
    summary = {
        "model_path": [model_path],
        "mAP50": [metrics.box.map50],
        "mAP50-95": [metrics.box.map],
        "Precision": [metrics.box.mp],
        "Recall": [metrics.box.mr],
    }
    
    df_summary = pd.DataFrame(summary)
    df_summary.to_csv(output_path, index=False)
    print(f"í•™ìŠµ ê²°ê³¼ ìš”ì•½ ì €ì¥: {output_path}")


def predict_with_tta(model, img_path, conf_threshold=0.5, iou_threshold=0.5, max_det=300):
    """
    Test Time Augmentationì„ ì‚¬ìš©í•œ ì¶”ë¡ 
    
    Args:
        model: YOLO ëª¨ë¸
        img_path: ì´ë¯¸ì§€ ê²½ë¡œ
        conf_threshold: Confidence threshold
        iou_threshold: NMS IoU threshold
        max_det: ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
    
    Returns:
        ì¶”ë¡  ê²°ê³¼
    """
    results = model.predict(
        img_path,
        imgsz=800,
        conf=conf_threshold,
        iou=iou_threshold,
        max_det=max_det,
        augment=True,  # TTA í™œì„±í™”
        verbose=False
    )
    
    return results[0]


def generate_submission(model_path, test_img_dir, category_mapping_path, 
                       output_path, conf_threshold=0.5, use_tta=False, iou_threshold=0.5, max_det=300):
    """
    Kaggle ì œì¶œìš© CSV íŒŒì¼ ìƒì„±
    
    Args:
        model_path: í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ
        test_img_dir: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
        category_mapping_path: Category mapping JSON íŒŒì¼ ê²½ë¡œ
        output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ
        conf_threshold: Confidence threshold (ê¸°ë³¸ê°’: 0.5, ë” ë†’ì€ ì •í™•ë„)
        use_tta: TTA ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, TTAëŠ” ë•Œë•Œë¡œ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦¼)
        iou_threshold: NMS IoU threshold (ê¸°ë³¸ê°’: 0.5, ë” ì—„ê²©í•œ í•„í„°ë§)
        max_det: ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
    """
    # ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # Category mapping ë¡œë“œ
    with open(category_mapping_path, "r") as f:
        mapping = json.load(f)
    idx2cat = {int(k): v for k, v in mapping["idx2cat"].items()}
    
    # ì œì¶œ íŒŒì¼ ìƒì„±
    submission = []
    ann_id = 1
    
    test_images = sorted([f for f in os.listdir(test_img_dir) if f.endswith(".png")])
    total_images = len(test_images)
    
    print(f"ì´ {total_images}ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
    print(f"ì„¤ì •: conf_threshold={conf_threshold}, iou_threshold={iou_threshold}, use_tta={use_tta}")
    
    for idx, img_name in enumerate(test_images, 1):
        if idx % 10 == 0 or idx == total_images:
            print(f"ì§„í–‰ ì¤‘... ({idx}/{total_images} ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ)")
        img_id = int(img_name.replace(".png", ""))
        img_path = os.path.join(test_img_dir, img_name)
        
        # ì¶”ë¡  (ë” ì—„ê²©í•œ ì„¤ì •)
        if use_tta:
            results = predict_with_tta(model, img_path, conf_threshold, iou_threshold, max_det)
        else:
            results = model.predict(
                img_path,
                imgsz=800,
                conf=conf_threshold,      # Confidence threshold
                iou=iou_threshold,        # NMS IoU threshold
                max_det=max_det,          # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
                verbose=False
            )[0]
        
        # Score ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ í•„í„°ë§ (confidenceê°€ ë‚®ì€ ì˜ˆì¸¡ ì œê±°)
        for box in results.boxes:
            cls = int(box.cls)
            score = float(box.conf)
            
            # Confidenceê°€ thresholdë³´ë‹¤ ë‚®ìœ¼ë©´ ì œì™¸
            if score < conf_threshold:
                continue
                
            orig_cid = idx2cat[cls]
            
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            w = x2 - x1
            h = y2 - y1
            
            # Bounding box ìœ íš¨ì„± ê²€ì‚¬ (ë„ˆë¬´ ì‘ê±°ë‚˜ ìŒìˆ˜ì¸ ê²½ìš° ì œì™¸)
            if w <= 0 or h <= 0 or x1 < 0 or y1 < 0:
                continue
            
            submission.append([
                ann_id, img_id, orig_cid,
                float(x1), float(y1), float(w), float(h), score
            ])
            ann_id += 1
    
    # CSV ì €ì¥
    df = pd.DataFrame(submission, columns=[
        "annotation_id", "image_id", "category_id",
        "bbox_x", "bbox_y", "bbox_w", "bbox_h", "score"
    ])
    
    df.to_csv(output_path, index=False)
    print(f"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ì´ ì˜ˆì¸¡ ê°œìˆ˜: {len(submission)}")
    
    return df


def find_existing_model(base_dir, model_name="pill_yolo_improved"):
    """
    ê¸°ì¡´ì— í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ê¸°
    
    Args:
        base_dir: í”„ë¡œì íŠ¸ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        model_name: ëª¨ë¸ ì´ë¦„
    
    Returns:
        ëª¨ë¸ ê²½ë¡œ ë˜ëŠ” None
    """
    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ í™•ì¸
    possible_paths = []
    
    # runs/detect ì•„ë˜ì˜ ì—¬ëŸ¬ ëª¨ë¸ ì´ë¦„ ë³€í˜• í™•ì¸
    model_name_variants = [model_name, f"{model_name}2", f"{model_name}3", f"{model_name}_2"]
    
    # base_dir ê¸°ì¤€ ê²½ë¡œ
    for variant in model_name_variants:
        possible_paths.append(
            os.path.join(base_dir, "runs", "detect", variant, "weights", "best.pt")
        )
        possible_paths.append(
            os.path.join(base_dir, variant, "weights", "best.pt")
        )
    
    # í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ê¸°ì¤€ ê²½ë¡œ
    for variant in model_name_variants:
        possible_paths.append(
            os.path.join(os.getcwd(), "runs", "detect", variant, "weights", "best.pt")
        )
    
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œë„ ê²€ìƒ‰
    parent_dirs = [
        os.path.dirname(base_dir),
        os.path.dirname(os.getcwd()),
    ]
    for parent_dir in parent_dirs:
        if parent_dir and os.path.exists(parent_dir):
            for variant in model_name_variants:
                possible_paths.append(
                    os.path.join(parent_dir, "runs", "detect", variant, "weights", "best.pt")
                )
    
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ê²½ë¡œ ì°¾ê¸°
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    return None


if __name__ == "__main__":
    import sys
    
    # ê²½ë¡œ ì„¤ì • (Windows í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
    BASE = r"D:/ìŠ¤í”„ë¦°íŠ¸AIì—”ì§€ë‹ˆì–´ ë¶€íŠ¸ìº í”„/part2_kaggle/6team_beginner_project"
    YOLO_DIR = os.path.join(BASE, "yolo_multiclass")
    TEST_IMG_DIR = os.path.join(BASE, "test_images")
    CATEGORY_MAPPING = os.path.join(BASE, "category_mapping.json")
    
    # ëª…ë ¹ì¤„ ì¸ì í™•ì¸ (--skip-training ë˜ëŠ” --inference-only)
    skip_training = "--skip-training" in sys.argv or "--inference-only" in sys.argv
    # --force-train ì˜µì…˜ì´ ìˆìœ¼ë©´ ê°•ì œë¡œ í•™ìŠµ
    force_train = "--force-train" in sys.argv
    
    # ì‹œë“œ ê³ ì •
    set_seed(42)
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 0 if torch.cuda.is_available() else "cpu"
    print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {'GPU' if device == 0 else 'CPU'}")
    
    # ê¸°ì¡´ ëª¨ë¸ ì°¾ê¸°
    existing_model = find_existing_model(BASE)
    
    # ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©
    if force_train:
        print("\nğŸ”„ --force-train ì˜µì…˜: ê°•ì œë¡œ ìƒˆë¡œ í•™ìŠµí•©ë‹ˆë‹¤.")
        skip_training = False
    elif existing_model:
        # ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš© (í•™ìŠµ ê±´ë„ˆë›°ê¸°)
        print(f"\nâœ… ê¸°ì¡´ ëª¨ë¸ ë°œê²¬: {existing_model}")
        print("í•™ìŠµì„ ê±´ë„ˆë›°ê³  ê¸°ì¡´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print("   (ìƒˆë¡œ í•™ìŠµí•˜ë ¤ë©´ --force-train ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”)")
        best_model_path = existing_model
        skip_training = True  # ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •
        # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ (ê²½ë¡œì—ì„œ)
        model_name = "pill_yolo_improved"  # ê¸°ë³¸ê°’
        for variant in ["pill_yolo_improved3", "pill_yolo_improved2", "pill_yolo_improved"]:
            if variant in best_model_path:
                model_name = variant
                break
    elif skip_training:
        # --skip-training ì˜µì…˜ì´ ìˆì§€ë§Œ ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°
        print("âš ï¸ --skip-training ì˜µì…˜ì´ ìˆì§€ë§Œ ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        skip_training = False
    else:
        # ê¸°ì¡´ ëª¨ë¸ë„ ì—†ê³  ì˜µì…˜ë„ ì—†ëŠ” ê²½ìš° â†’ í•™ìŠµ ì‹œì‘
        print("\nğŸ’¡ ê¸°ì¡´ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
        skip_training = False
    
    if not skip_training:
        # 1. ëª¨ë¸ í•™ìŠµ
        print("\n=== ëª¨ë¸ í•™ìŠµ ì‹œì‘ ===")
        train_result = train_improved_model(BASE, YOLO_DIR, device=device, epochs=50)
        best_model_path = train_result["model_path"]
        model_name = train_result["model_name"]
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {best_model_path}")
        
        # 2. ê²€ì¦
        print("\n=== ëª¨ë¸ ê²€ì¦ ===")
        if os.path.exists(best_model_path):
            metrics = validate_model(best_model_path, os.path.join(YOLO_DIR, "dataset.yaml"), device)
            
            # í•™ìŠµ ê²°ê³¼ ìš”ì•½ ì €ì¥
            summary_path = os.path.join(BASE, f"training_summary_{model_name}.csv")
            save_training_summary(best_model_path, metrics, summary_path)
        else:
            print(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {best_model_path}")
            print("í•™ìŠµì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ê²½ë¡œê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            exit(1)
    else:
        # ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš© ì‹œ ê²€ì¦ì€ ì„ íƒì‚¬í•­
        print("\nğŸ’¡ ê¸°ì¡´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ê²€ì¦ì€ ê±´ë„ˆëœë‹ˆë‹¤.")
        print(f"   ëª¨ë¸ ê²½ë¡œ: {best_model_path}")
    
    # 3. ì œì¶œ íŒŒì¼ ìƒì„±
    print("\n=== ì œì¶œ íŒŒì¼ ìƒì„± ===")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ í™•ì¸
    if not os.path.exists(TEST_IMG_DIR):
        print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {TEST_IMG_DIR}")
        print("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì¤€ë¹„í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
    else:
        # ì œì¶œ íŒŒì¼ ê²½ë¡œ (ëª¨ë¸ ì´ë¦„ í¬í•¨)
        output_path = os.path.join(BASE, f"kaggle_submission_{model_name}.csv")
        
        print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬: {TEST_IMG_DIR}")
        print(f"ì¶œë ¥ íŒŒì¼: {output_path}")
        
        try:
            # ê°œì„ ëœ íŒŒë¼ë¯¸í„°ë¡œ ì œì¶œ íŒŒì¼ ìƒì„±
            # conf_thresholdë¥¼ 0.5ë¡œ ë†’ì—¬ False Positive ê°ì†Œ
            # use_ttaë¥¼ Falseë¡œ ì„¤ì • (TTAëŠ” ë•Œë•Œë¡œ ì„±ëŠ¥ì„ ë–¨ì–´ëœ¨ë¦¼)
            # iou_thresholdë¥¼ 0.5ë¡œ ì„¤ì •í•˜ì—¬ ë” ì—„ê²©í•œ NMS
            df = generate_submission(
                best_model_path,
                TEST_IMG_DIR,
                CATEGORY_MAPPING,
                output_path,
                conf_threshold=0.5,      # 0.25 â†’ 0.5 (ë” ë†’ì€ ì •í™•ë„)
                use_tta=False,           # TTA ë¹„í™œì„±í™” (ì„±ëŠ¥ ê°œì„ )
                iou_threshold=0.5,      # 0.7 â†’ 0.5 (ë” ì—„ê²©í•œ NMS)
                max_det=300             # ìµœëŒ€ ê²€ì¶œ ê°œìˆ˜
            )
            
            # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
            print(f"\nğŸ“Š ì œì¶œ íŒŒì¼ ìš”ì•½:")
            print(f"  - ì´ ì˜ˆì¸¡ ê°œìˆ˜: {len(df)}")
            print(f"  - ê³ ìœ  ì´ë¯¸ì§€ ìˆ˜: {df['image_id'].nunique()}")
            print(f"  - ê³ ìœ  ì¹´í…Œê³ ë¦¬ ìˆ˜: {df['category_id'].nunique()}")
            print(f"  - í‰ê·  Confidence: {df['score'].mean():.4f}")
            print(f"  - ìµœì†Œ Confidence: {df['score'].min():.4f}")
            print(f"  - ìµœëŒ€ Confidence: {df['score'].max():.4f}")
            
        except Exception as e:
            print(f"âŒ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "="*50)
    print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    print("="*50)

